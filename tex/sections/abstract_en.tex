\Abstract{}

The detection of similarities withing the time series provided by the Google $n$-gram data can help researchers to explore and understand relationships between concrete words and abstract concepts. We construct a way of expressing this similarity and explain why this is, in our opinion, a sane approach.

Another important aspect of handling this kind of data in large scale the existence of an index structure for this task. We show how the prior art performs and why the time series data set is different from many other data sets. We then explore another way of exploiting similar information between time series to construct an index and compress the data at the same time. Afterwards, we show why our approach might have some essential issues and discuss some possible workarounds.

After presenting our way of implementing tools in this domain, we run a wide set of evaluations regarding the semantic meaning of our similarity metric, the effect of the compression on the query processing, the filter design that uses our system as an index and finally performance measurements.

We end this work with some conclusions about the, not necessary great, results, and give an outlook on future research and what, in our opinion, might be other approaches worth to try.
