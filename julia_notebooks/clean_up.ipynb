{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input clean up\n",
    "\n",
    "We perform the following clean up steps:\n",
    "1. Download the raw data from Google and extract all possible nGrams\n",
    "2. Filter out entries that contain the followig characterclass `[_.,!'0-9]`\n",
    "3. Apply NFKC normalization, lowercase and deduplicate all inputs\n",
    "4. Run WordNet lemmatizer and snowball stemmer\n",
    "5. Prue entries with $\\sum_{y} var_{0, y} < 1000$\n",
    "\n",
    "*NOTE: Swapping 2. and 3. does **not** lead to a different output*\n",
    "\n",
    "| Dataset | raw     | filtered | normalized | stems   | pruned |\n",
    "|---------|---------|----------|------------|---------|--------|\n",
    "| d       | 981'466 | 341'819  | 249'790    | 188'481 | 38'220 | \n",
    "| k       | 536'396 | 222'419  | 172'642    | 150'450 | 30'335 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.3",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
